{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c1f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "780d0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleEnvironment:\n",
    "    def __init__(self):\n",
    "        self.steps_left=20\n",
    "        \n",
    "\n",
    "    def get_observation(self)-> List[float]:\n",
    "        return [0.0,0.0,0.0]\n",
    "    \n",
    "    def get_action(self)-> List[int]:\n",
    "        return [0,1]\n",
    "    \n",
    "    def is_done(self)-> bool:\n",
    "        return self.steps_left==0\n",
    "    \n",
    "    def action(self,action:int)-> float:\n",
    "        if self.is_done():\n",
    "            raise Exception(\"Game is over\")\n",
    "        self.steps_left-=1\n",
    "        return random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef78c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.total_reward=0.0\n",
    "        \n",
    "    def step(self,env:SampleEnvironment):\n",
    "        current_obs=env.get_observation()\n",
    "        print(\"Observation {}\".format(current_obs))\n",
    "        actions=env.get_action()\n",
    "        print(\"Action {}\".format(actions))\n",
    "        reward=env.action(random.choice(actions))\n",
    "        self.total_reward+=reward\n",
    "        print(\"Reward {}\".format(self.total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef60ba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 0.5577307089304333\n",
      "step 2\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 0.6509260055356497\n",
      "step 3\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 1.2996561136958795\n",
      "step 4\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 1.5268724695819365\n",
      "step 5\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 1.6360473643721738\n",
      "step 6\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 2.182689554312641\n",
      "step 7\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 2.57037522631661\n",
      "step 8\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 3.1836304143494996\n",
      "step 9\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 4.129393952278772\n",
      "step 10\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 4.306412717798295\n",
      "step 11\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 5.2412177747898046\n",
      "step 12\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 6.050208118042963\n",
      "step 13\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 6.051377914839773\n",
      "step 14\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 6.596839983823289\n",
      "step 15\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 6.860549780692125\n",
      "step 16\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 7.313640456525587\n",
      "step 17\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 7.760840771217186\n",
      "step 18\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 7.806750493505376\n",
      "step 19\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 7.90905874442801\n",
      "step 20\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 8.146299119726104\n",
      "Total reward got:8.1463\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    env=SampleEnvironment()\n",
    "    agent=Agent()\n",
    "    i=0\n",
    "    \n",
    "    while not env.is_done():\n",
    "        i=i+1\n",
    "        print(\"step {}\".format(i))\n",
    "        agent.step(env)\n",
    "        \n",
    "    print(\"Total reward got:%.4f\"%agent.total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6f364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
